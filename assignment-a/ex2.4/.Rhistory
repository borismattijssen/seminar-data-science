1 + 2
license()
demo()
image()
image
image.default()
image.default
table(train)
train
train <- merge(train_labels, train_values)
table(train)
# Define train_values_url
train_values_url <- "http://s3.amazonaws.com/drivendata/data/7/public/4910797b-ee55-40a7-8668-10efd5c1b960.csv"
# Import train_values
train_values <- read.csv(train_values_url)
# Define train_labels_url
train_labels_url <- "http://s3.amazonaws.com/drivendata/data/7/public/0bf8bc6e-30d0-4c50-956a-603fc693d966.csv"
# Import train_labels
train_labels <- read.csv(train_labels_url)
# Define test_values_url
test_values_url <- "http://s3.amazonaws.com/drivendata/data/7/public/702ddfc5-68cd-4d1d-a0de-f5f566f76d91.csv"
# Import test_values
test_values <- read.csv(test_values_url)
train <- merge(train_labels, train_values)
table(train)
View(train)
# use rstudioapi package to get file directory
library(rstudioapi)
# set working directory to match this file's directory
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
#install.packages("twitteR", dependencies = TRUE)
library(twitteR)
#install.packages("RCurl", dependencies = T)
library(RCurl)
#install.packages("bitops", dependencies = T)
library(bitops)
#install.packages("plyr", dependencies = T)
library(plyr)
#install.packages('stringr', dependencies = T)
library(stringr)
#install.packages("NLP", dependencies = T)
library(NLP)
#install.packages("tm", dependencies = T)
library(tm)
#install.packages("wordcloud", dependencies=T)
#install.packages("RColorBrewer", dependencies=TRUE)
library(RColorBrewer)
library(wordcloud)
#install.packages("reshape", dependencies=T)
library(reshape)
library(car) #Package includes Levene's test
clearTweets <- function(tweets, excl) {
tweets.text <- sapply(tweets, function(t)t$getText()) #get text out of tweets
tweets.text = gsub('[[:cntrl:]]', '', tweets.text)
tweets.text = gsub('\\d+', '', tweets.text)
tweets.text <- str_replace_all(tweets.text,"[^[:graph:]]", " ") #remove graphic
corpus <- Corpus(VectorSource(tweets.text))
corpus_clean <- tm_map(corpus, removePunctuation)
corpus_clean <- tm_map(corpus_clean, content_transformer(tolower))
corpus_clean <- tm_map(corpus_clean, removeWords, stopwords("english"))
corpus_clean <- tm_map(corpus_clean, removeNumbers)
corpus_clean <- tm_map(corpus_clean, stripWhitespace)
corpus_clean <- tm_map(corpus_clean, removeWords, c(excl,"http","https","httpst"))
return(corpus_clean)
}
source("your_twitter.R") #this file will set my personal variables for my twitter app, adjust the name of this file. use the provide template your_twitter.R
setup_twitter_oauth(consumer_key,consumer_scret, access_token,access_scret) #connect to  twitter app
tweets_T <- searchTwitter("#JustinBieber", n=1000, lang="en", resultType="recent") #1000 recent tweets about Donald Trump, in English (I think that 1500 tweets is max)
tweets_C <- searchTwitter("#BenedictCumberbatch", n=1000, lang="en", resultType="recent") #1000 recent tweets about Hillary Clinton
tweets_B <- searchTwitter("#obama", n=1000, lang="en", resultType="recent") #1000 recent tweets about Bernie Sanders
# based on https://youtu.be/JoArGkOpeU0
corpus_T<-clearTweets(tweets_T, c("trump","amp","realdonaldtrump","trumptrain","donald","trumps","alwaystrump")) #remove also some campain slogans
wordcloud(corpus_T, max.words=50)
corpus_C<-clearTweets(tweets_C, c("hillary","amp","clinton","hillarys"))
wordcloud(corpus_C,  max.words=50)
corpus_B<-clearTweets(tweets_B, c("bernie", "amp", "sanders","bernies"))
wordcloud(corpus_B,  max.words=50)
tweets_T.text <- laply(tweets_T, function(t)t$getText()) #get text out of tweets
tweets_C.text <- laply(tweets_C, function(t)t$getText()) #get text out of tweets
tweets_B.text <- laply(tweets_B, function(t)t$getText()) #get text out of tweets
#taken from https://github.com/mjhea0/twitter-sentiment-analysis
pos <- scan('positive-words.txt', what = 'character', comment.char=';') #read the positive words
neg <- scan('negative-words.txt', what = 'character', comment.char=';') #read the negative words
source("sentiment3.R") #load algoritm
analysis_T <- score.sentiment(tweets_T.text, pos, neg)
analysis_C <- score.sentiment(tweets_C.text, pos, neg)
analysis_B <- score.sentiment(tweets_B.text, pos, neg)
sem<-data.frame(analysis_T$score, analysis_C$score, analysis_B$score)
semFrame <-melt(sem, measured=c(analysis_T.score,analysis_C.score, analysis_B.score ))
names(semFrame) <- c("Candidate", "score")
semFrame$Candidate <-factor(semFrame$Candidate, labels=c("Justin Bieber", "Benedict Cumberbatch", "Barack Obama")) # change the labels for your celibrities
#subquestion 6 - post hoc analysis if needed
pairwise.t.test(semFrame$score, semFrame$Candidate, paired = FALSE, p.adjust.method = "bonferroni")
library(car)
library(ggplot2)
library(nlme)
library(reshape)
library(graphics)
library(QuantPsyc) #include lm.beta()
# use rstudioapi package to get file directory
library(rstudioapi)
# set working directory to match this file's directory
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
q3 <- read.csv("hybrid_reg.csv",header = TRUE)
#subquestion 2 - histogram of dependent variable
hist(q3$msrp)
hist(q3$)
boris <- lm(semFrame$score ~ 1)
abline(coef(fit))
abline(coef(boris))
abline(1coef(boris))
abline(1,coef(boris))
abline(1,coef(boris))
y <- rnorm(1000)
plot(y)
plot(lm(y ~ 1))
plot(y)
plot(lm(y ~ 1))
# use rstudioapi package to get file directory
library(rstudioapi)
# set working directory to match this file's directory
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
# load the webvisit file (2 + 25 + 24 mod 3 = 0)
WebVisit <- read.csv(file="./webvisit0.csv", header=TRUE, sep=",")
# shapiro-wilk test for normal distribution
shapiro.test(WebVist$pages)
# shapiro-wilk test for normal distribution
shapiro.test(WebVisit$pages)
shapiro.test(y)
y
plot(length(y),y)
plot(range(length(y)),y)
plot(range(0,length(y)),y)
plot(range(1,length(y)),y)
range(length(y))
length(y)
range(1000)
plot(1:length(y),y)
y <- rnorm(1000)
shapiro.test(y)
model0 <- glm(Gender ~ 1, data = q4, family = binomial())
model1 <- glm(Gender ~ Head.Size , data = q4, family = binomial())
library(car) #Package includes Levene's test
#install.packages('tidyr',dependencies = TRUE)
library(tidyr)  # for wide to long format transformation of the data
library(ggplot2)
#install.packages('QuantPsyc',dependencies = TRUE)
library(QuantPsyc) #include lm.beta()
#install.packages('gmodels',dependencies = TRUE)
library(gmodels)
# use rstudioapi package to get file directory
library(rstudioapi)
# set working directory to match this file's directory
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
logisticPseudoR2s <- function(LogModel)
#taken from Andy Fields et al. book on R, p.334
{
dev <- LogModel$deviance
nullDev <- LogModel$null.deviance
modelN <- length(LogModel$fitted.values)
R.l <- 1 - dev / nullDev
R.cs <- 1 - exp(-(nullDev - dev) / modelN)
R.n <- R.cs / (1 - (exp(-(nullDev / modelN))))
cat("Pseudo R^2 for logistic regression\n")
cat("Hosmer and Lemshow R^2:  ", round(R.l, 3), "\n")
cat("Cox and Snell R^2:       ", round(R.cs, 3), "\n")
cat("Nagelkerke R^2:          ", round(R.n, 3), "\n")
}
q4 <- read.csv("ex2.4_dataset.csv", header=TRUE)
#binomial accepts only 0 and 1 values, not 2
q4$Gender[q4$Gender == 2] <- 0
q4$Age.Range[q4$Age.Range== 2] <- 0
#Centering predictors, this will make easier to interpret predictors
q4$Head.Size <-q4$Head.Size - mean(q4$Head.Size)
q4$Brain.Weight <-q4$Brain.Weight - mean(q4$Brain.Weight)
model0 <- glm(Gender ~ 1, data = q4, family = binomial())
model1 <- glm(Gender ~ Head.Size , data = q4, family = binomial())
model2 <- glm(Gender ~ Brain.Weight, data = q4, family = binomial())
anova(model0, model2)
anova(model0, model1)
model1 <- glm(Gender ~ Head.Size , data = q4, family = binomial())
model2 <- glm(Gender ~ Head.Size + Brain.Weight, data = q4, family = binomial())
#TODO, find out which one of model1 or model2 is better and use it in following commands
anova(model0,model1,model2,test = "Chisq" )
#TODO, find out which one of model1 or model2 is better and use it in following commands
anova(model0,model2,test = "Chisq" )
#TODO, find out which one of model1 or model2 is better and use it in following commands
anova(model0,model2)
#TODO, find out which one of model1 or model2 is better and use it in following commands
anova(model0,model2,test = "Chisq" )
#TODO, find out which one of model1 or model2 is better and use it in following commands
anova(model0,model1,test = "Chisq" )
anova(model0,model2,test = "Chisq" )
model1 <- glm(Gender ~ Head.Size , data = q4, family = binomial())
model2 <- glm(Gender ~ Brain.Weight, data = q4, family = binomial())
#TODO, find out which one of model1 or model2 is better and use it in following commands
anova(model0,model1,test = "Chisq" )
anova(model0,model2,test = "Chisq" )
model0 <- glm(Gender ~ 1, data = q4, family = binomial())
model1 <- glm(Gender ~ Head.Size , data = q4, family = binomial())
model2 <- glm(Gender ~ Brain.Weight, data = q4, family = binomial())
#TODO, find out which one of model1 or model2 is better and use it in following commands
anova(model0,model1,test = "Chisq" )
anova(model1,model0,test = "Chisq" )
model3 <- glm(Gender ~ Head.Size + Brain.Weight, data = q4, family = binomial())
#need to check which model improves data and keep only that
logisticPseudoR2s(model3)
