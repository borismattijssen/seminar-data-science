1 + 2
license()
demo()
image()
image
image.default()
image.default
table(train)
train
train <- merge(train_labels, train_values)
table(train)
# Define train_values_url
train_values_url <- "http://s3.amazonaws.com/drivendata/data/7/public/4910797b-ee55-40a7-8668-10efd5c1b960.csv"
# Import train_values
train_values <- read.csv(train_values_url)
# Define train_labels_url
train_labels_url <- "http://s3.amazonaws.com/drivendata/data/7/public/0bf8bc6e-30d0-4c50-956a-603fc693d966.csv"
# Import train_labels
train_labels <- read.csv(train_labels_url)
# Define test_values_url
test_values_url <- "http://s3.amazonaws.com/drivendata/data/7/public/702ddfc5-68cd-4d1d-a0de-f5f566f76d91.csv"
# Import test_values
test_values <- read.csv(test_values_url)
train <- merge(train_labels, train_values)
table(train)
View(train)
library(rstudioapi)
library(robustHD)
library(car)
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
d <- read.csv("data.csv")
top3
# remove outliers from the ap metric
d2 <- subset(d, (d$metric != 'ap' | !d$score %in% boxplot.stats(d$score[d$metric == 'ap'])$out))
# standardize scores
d2$score[d2$metric == 'ap'] = (d2$score[d2$metric == 'ap'] - mean(d2$score[d2$metric == 'ap'])) / sd(d2$score[d2$metric == 'ap'])
d2$score[d2$metric == 'err'] = (d2$score[d2$metric == 'err'] - mean(d2$score[d2$metric == 'err'])) / sd(d2$score[d2$metric == 'err'])
d2$score[d2$metric == 'ndcg'] = (d2$score[d2$metric == 'ndcg'] - mean(d2$score[d2$metric == 'ndcg'])) / sd(d2$score[d2$metric == 'ndcg'])
d2$score[d2$metric == 'p10'] = (d2$score[d2$metric == 'p10'] - mean(d2$score[d2$metric == 'p10'])) / sd(d2$score[d2$metric == 'p10'])
d2$score[d2$metric == 'rbp'] = (d2$score[d2$metric == 'rbp'] - mean(d2$score[d2$metric == 'rbp'])) / sd(d2$score[d2$metric == 'rbp'])
# only select dataset trec10
d3 <- subset(d2, d2$dataset == 'trec10')
s <- sort(systems$`d3$score`, index.return=TRUE, decreasing = TRUE)
# pick top 3 systems
systems <- aggregate(d3$score ~ d3$token + d3$lug + d3$model, FUN=mean)
s <- sort(systems$`d3$score`, index.return=TRUE, decreasing = TRUE)
top3 <- systems[s$ix[0:3],]
top3
#create a different subset for each best system combination of two steady components, token has not been compared yet
d4 <- subset(d3,d3$token=="terrier" & d3$model=="dph")
d5 <- subset(d3,d3$token=="terrier" & d3$lug=="snowballPorter")
d6 <- subset(d3,d3$token=="terrier" & d3$lug=="porter")
d7 <- subset(d3,d3$token=="terrier" & d3$model=="jskls")
#create a model for each of the subsets created above
#model2 <- lm(score ~ token, data = d4, na.action = na.exclude)
model3 <- lm(score ~ model, data = d5, na.action = na.exclude)
model4 <- lm(score ~ lug, data = d4, na.action = na.exclude)
model5 <- lm(score ~ model, data = d6, na.action = na.exclude)
model6 <- lm(score ~ lug, data = d7, na.action = na.exclude)
#get the coeffcients for the component variable of each model and check its statistical properties
model <- coef(model3)
sd(model)
mean(model)
sum(model)
summary(model3)
model
plot(model3)
plot(d5$score, d5$model)
plot(d5$model, d5$score)
plot(d6$model, d6$score)
scatter(d5$model, d5$score)
scatterplot(d5$model, d5$score)
scatterplot(model3)
scatterplot(score ~ model, data = d5)
d5$model, d5$score
scatterplot(d5$model, d5$score)
plot(d5$model, d5$score)
#get the coeffcients for the component variable of each model and check its statistical properties
model <- coef(model3)
plot(d6$model, d6$score)
plot(d5$model, d5$score)
# avg scores per model
m4 <- mean(d4$score)
m5 <- mean(d5$score)
m6 <- mean(d6$score)
m7 <- mean(d7$score)
# avg scores per model
lugmean <- mean(d4$score) + mean(d7$score)
modelmean <- mean(d5$score) + mean(d6$score)
lugmean
modelmean
# avg scores per model
lugmean <- mean(d4$score) + mean(d7$score)
modelmean <- mean(d5$score) + mean(d6$score)
lugmean
modelmean
anova(m)
dx <- subset(d3,d3$token=="terrier" & (d3$model=="dph" | d3$model=="jskls"))
m <- lm(score ~ lug, data=dx, na.action = na.exclude)
anova(m)
dx2 <- subset(d3,d3$token=="terrier" & (d3$lug=="snowballPorter" | d3$lug=="porter"))
m2 <- lm(score ~ model, data=dx2, na.action = na.exclude)
anova(m2)
d_token <- subset(d3,
(d3$model=="dph" | d3$model=="jskls")  &
(d3$lug=="snowballPorter" | d3$lug=="porter")
)
model_token <- lm(score ~ token, data=d_token, na.action = na.exclude)
anova(model_token)
d_lug <- subset(d3,d3$token=="terrier" & (d3$model=="dph" | d3$model=="jskls"))
model_lug <- lm(score ~ lug, data=d_lug, na.action = na.exclude)
anova(model_lug)
d_model <- subset(d3,d3$token=="terrier" & (d3$lug=="snowballPorter" | d3$lug=="porter"))
model_model <- lm(score ~ model, data=d_model, na.action = na.exclude)
anova(model_model)
d_token <- subset(d3,
(d3$model=="dph" | d3$model=="jskls")  &
(d3$lug=="snowballPorter" | d3$lug=="porter")
)
model_token <- lm(score ~ token, data=d_token, na.action = na.exclude)
anova(model_token)
#use linear model to predict scores with dataset and topic variables for the initial dataset and the one with the standardized aggregated scores
model <- lm(score ~ dataset + topic,data=d,na.action = na.exclude)
model1 <- lm(score ~ dataset + topic,data=d2,na.action = na.exclude)
#use the summaries to compare the systems because ANOVA can't be performed for different dataset sizes
summary(model)
summary(model1)
